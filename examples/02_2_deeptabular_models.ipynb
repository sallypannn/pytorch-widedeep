{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `deeptabular` component\n",
    "\n",
    "In the previous notebook I described the linear model (`Wide`) and the standard text and image classification and regression models (`DeepText` and `DeepImage`) that can be used as the `wide`, `deeptext` and `deepimage` components respectively when building a `WideDeep` model. \n",
    "\n",
    "In this notebook I will describe the different models (or architectures) available in `pytorch-widedeep` that can be used as the `deeptabular` model. Note that the `deeptabular` model alone is what normally would be referred as Deep Learning for tabular data. As I mentioned in previous notebooks, each component can be used independently. Therefore, if you wanted to use `deeptabular` alone it is perfectly possible. There are just a couple of simple requirement that will be covered in a later notebook.\n",
    "\n",
    "The models available in `pytorch-widedeep` as the `deeptabular` component are:\n",
    "\n",
    "1. `TabMlp`\n",
    "2. `TabResnet`\n",
    "3. `Tabnet`\n",
    "4. `TabTransformer`\n",
    "5. `FT-Tabransformer` (which is a simple variation of the `TabTransformer`)\n",
    "6. `SAINT`\n",
    "\n",
    "Let's have a close look to the 6 of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. `TabMlp`\n",
    "\n",
    "`TabMlp` is the simples architecture and is very similar to the tabular model available in the fantastic fastai library. In fact, the implementation of the dense layers of the MLP is mostly identical to that in that library.\n",
    "\n",
    "The figure below illustrate the `TabMlp` architecture:\n",
    "\n",
    "<img src=\"../docs/figures/tabmlp_arch.png\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "The dashed-border boxes indicate that these components are optional. For example, we could use `TabMlp` without categorical components, or without continuous components, if we wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/javier/.pyenv/versions/3.7.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_widedeep.models import TabMlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TabMlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look to a model and one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['a', 'b', 'c', 'd', 'e']\n",
    "X_tab = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n",
    "embed_input = [(u,i,j) for u,i,j in zip(colnames[:4], [4]*4, [8]*4)]\n",
    "column_idx = {k:v for v,k in enumerate(colnames)}\n",
    "tabmlp = TabMlp(mlp_hidden_dims=[8,4], continuous_cols=['e'], column_idx=column_idx, \n",
    "                embed_input=embed_input, cont_norm_layer=\"batchnorm\")\n",
    "out = tabmlp(X_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabMlp(\n",
       "  (embed_layers): ModuleDict(\n",
       "    (emb_layer_a): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_b): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_c): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_d): Embedding(5, 8, padding_idx=0)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cont_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (tab_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=33, out_features=8, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Dropout(p=0.1, inplace=False)\n",
       "        (1): Linear(in_features=8, out_features=4, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabmlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the input dimension of the MLP is `33`, `32` from the embeddings and `1` for the continuous features. Before we move on, is worth commenting an aspect that applies to all models discussed here. The `TabPreprocessor` included in this package gives the user the possibility of standarising the input via `sklearn`'s `StandardScaler`. Alternatively, or in addition to it, it is possible to add a continuous normalization layer (`BatchNorm1d` or `LayerNorm`). To do so simply set the `cont_norm_layer` as indicated in the example above. See also the docs.\n",
    "\n",
    "I will insist on this in this and the following sections. Note that `TabMlp` (or any of the wide and deep components) does not build the final connection with the final neuron(s). This is done by the ``WideDeep`` class, which collects all wide and deep components and connects them to the output neuron(s).\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import WideDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_model = WideDeep(deeptabular=tabmlp, pred_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideDeep(\n",
       "  (deeptabular): Sequential(\n",
       "    (0): TabMlp(\n",
       "      (embed_layers): ModuleDict(\n",
       "        (emb_layer_a): Embedding(5, 8, padding_idx=0)\n",
       "        (emb_layer_b): Embedding(5, 8, padding_idx=0)\n",
       "        (emb_layer_c): Embedding(5, 8, padding_idx=0)\n",
       "        (emb_layer_d): Embedding(5, 8, padding_idx=0)\n",
       "      )\n",
       "      (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "      (cont_norm): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (tab_mlp): MLP(\n",
       "        (mlp): Sequential(\n",
       "          (dense_layer_0): Sequential(\n",
       "            (0): Dropout(p=0.1, inplace=False)\n",
       "            (1): Linear(in_features=33, out_features=8, bias=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (dense_layer_1): Sequential(\n",
       "            (0): Dropout(p=0.1, inplace=False)\n",
       "            (1): Linear(in_features=8, out_features=4, bias=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "voila"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. `TabResnet`\n",
    "\n",
    "`TabResnet` is very similar to `TabMlp`, but the embeddings (or the concatenation of embeddings and continuous features) are passed through a series of Resnet blocks built with dense layers. This is probably the most flexible `deeptabular` component in terms of the many variants one can define via the parameters. Let's have a look to the architecture:\n",
    "\n",
    "<img src=\"../docs/figures/tabresnet_arch.png\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "The dashed-border boxes indicate the the component is optional and the dashed lines indicate the different paths or connections present depending on which components we decide to include. For example, we could chose to concatenate the continuous features, normalized or not via a `BatchNorm1d` layer, with the embeddings and pass the result of such a concatenation trough the series of Resnet blocks. Alternatively, we might prefer to concatenate the continuous features with the results of passing the embeddings through the Resnet blocks. Another optional component is the MLP before the output neuron(s). If not MLP is present, the output from the Resnet blocks or the results of concatenating that output with the continuous features (normalised or not) will be connected directly to the output neuron(s). \n",
    "\n",
    "Each Resnet block is comprised by the following operations:\n",
    "\n",
    "<img src=\"../docs/figures/resnet_block.png\" width=\"350\" align=\"center\"/>\n",
    "\n",
    "For more details see [`pytorch_widedeep/models/tab_resnet.BasicBlock`](https://github.com/jrzaurin/pytorch-widedeep/blob/master/pytorch_widedeep/models/tab_resnet.py). \n",
    "\n",
    "Let's have a look to an example now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import TabResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TabResnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n",
    "colnames = ['a', 'b', 'c', 'd', 'e']\n",
    "embed_input = [(u,i,j) for u,i,j in zip(colnames[:4], [4]*4, [8]*4)]\n",
    "column_idx = {k:v for v,k in enumerate(colnames)}\n",
    "tabresnet = TabResnet(blocks_dims=[16,16,16], \n",
    "                  column_idx=column_idx, \n",
    "                  embed_input=embed_input,\n",
    "                  continuous_cols = ['e'],\n",
    "                  cont_norm_layer = \"layernorm\",\n",
    "                  concat_cont_first = False, \n",
    "                  mlp_hidden_dims = [16, 4],\n",
    "                  mlp_dropout = 0.5)\n",
    "out = tabresnet(X_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabResnet(\n",
       "  (embed_layers): ModuleDict(\n",
       "    (emb_layer_a): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_b): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_c): Embedding(5, 8, padding_idx=0)\n",
       "    (emb_layer_d): Embedding(5, 8, padding_idx=0)\n",
       "  )\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cont_norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "  (tab_resnet_blks): DenseResnet(\n",
       "    (dense_resnet): Sequential(\n",
       "      (lin1): Linear(in_features=32, out_features=16, bias=True)\n",
       "      (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (block_0): BasicBlock(\n",
       "        (lin1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (leaky_relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (lin2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (block_1): BasicBlock(\n",
       "        (lin1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (leaky_relu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        (dp): Dropout(p=0.1, inplace=False)\n",
       "        (lin2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tab_resnet_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Linear(in_features=17, out_features=16, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabresnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, first the embeddings are concatenated (resulting in a tensor of dim ($*$, 32) and are projected (or resized, which happens in `lin1` and `bn1`) to the input dimension of the Resnet block (16). The we have the two Resnet blocks defined by the sequence `[INP1 (16) -> OUT1 == INP2 (16) -> OUT2 (16)]`. Finally the output from the Resnet blocks is concatenated and passed to the MLP. \n",
    "\n",
    "As I mentioned earlier, note that `TabResnet` does not build the connection to the output neuron(s). This is done by the ``WideDeep`` class, which collects all wide and deep components and connects them to the output neuron(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. `Tabnet`\n",
    "\n",
    "Details on this architecture can be found in [TabNet: Attentive Interpretable Tabular Learning](https://arxiv.org/pdf/1908.07442.pdf). This is not a simple algorithm. Therefore, I strongly recommend reading the paper.\n",
    "\n",
    "In general terms, `Tabnet` takes the embeddings from the categorical columns and the continuous columns (standarised or not) that are then passed through a series of `Steps`. Each `Step` involves a so called Attentive Transformer and a Feature Transformer, combined with masking and a `Relu` non-linearity. This is shown in the figure below, directly taken from the paper. The part of the diagram drawn as $[FC \\rightarrow out]$ would be what in other figures I draw as $[MLP -> output \\space neuron]$.\n",
    "\n",
    "<img src=\"../docs/figures/tabnet_arch_1.png\" width=\"600\" align=\"center\"/>\n",
    "<img src=\"../docs/figures/tabnet_arch_2.png\" width=\"600\" align=\"center\"/>\n",
    "\n",
    "Note that in the paper the authors use an encoder-decoder architecture and apply a routine that involves unsupervised pre-training plus supervised fine-tunning. However the authors found that unsupervised pre-training is useful when the data size is very small and/or there is a large number of unlabeled observations. This result is consistent with those obtained by subsequent papers using the same approach. \n",
    "\n",
    "`pytorch-widedeep` was conceived as a library to use wide and deep models with tabular data, images and text for supervised learning (regression or classification). Therefore, I decided to implement only the encoder architecture of this model, and the transformer-based models. \n",
    "\n",
    "If you want more details on each component I recommend reading the paper and have a look to the implementation by the guys at [dreamquark-ai](https://github.com/dreamquark-ai/tabnet). In fact, and let me make this clear, **the Tabnet implementation in this package is mostly a copy and paste from that at the dreamquark-ai's library**. Simply, I have adapted it to work with wide and deep models and I have added a few extras, such as being able to add dropout in the GLU blocks or to not use Ghost batch normalization. \n",
    "\n",
    "Enough writing, let's have a look to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_tab = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n",
    "colnames = ['a', 'b', 'c', 'd', 'e']\n",
    "embed_input = [(u,i,j) for u,i,j in zip(colnames[:4], [4]*4, [8]*4)]\n",
    "column_idx = {k:v for v,k in enumerate(colnames)}\n",
    "tabnet = TabNet(\n",
    "        column_idx=column_idx,\n",
    "        embed_input=embed_input,\n",
    "        continuous_cols=['e'],\n",
    "        cont_norm_layer = \"batchnorm\",\n",
    "        ghost_bn = False,\n",
    "    )\n",
    "out = tabnet(X_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabNet(\n",
       "  (embed_and_cont): EmbeddingsAndContinuous(\n",
       "    (embed_layers): ModuleDict(\n",
       "      (emb_layer_a): Embedding(5, 8, padding_idx=0)\n",
       "      (emb_layer_b): Embedding(5, 8, padding_idx=0)\n",
       "      (emb_layer_c): Embedding(5, 8, padding_idx=0)\n",
       "      (emb_layer_d): Embedding(5, 8, padding_idx=0)\n",
       "    )\n",
       "    (embedding_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (cont_norm): Identity()\n",
       "  )\n",
       "  (tabnet_encoder): TabNetEncoder(\n",
       "    (initial_bn): BatchNorm1d(33, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    (initial_splitter): FeatTransformer(\n",
       "      (shared): GLU_Block(\n",
       "        (glu_layers): ModuleList(\n",
       "          (0): GLU_Layer(\n",
       "            (fc): Linear(in_features=33, out_features=32, bias=False)\n",
       "            (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            (dp): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): GLU_Layer(\n",
       "            (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "            (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            (dp): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (step_dependent): GLU_Block(\n",
       "        (glu_layers): ModuleList(\n",
       "          (0): GLU_Layer(\n",
       "            (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "            (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            (dp): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (1): GLU_Layer(\n",
       "            (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "            (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "            (dp): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feat_transformers): ModuleList(\n",
       "      (0): FeatTransformer(\n",
       "        (shared): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=33, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (step_dependent): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): FeatTransformer(\n",
       "        (shared): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=33, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (step_dependent): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): FeatTransformer(\n",
       "        (shared): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=33, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (step_dependent): GLU_Block(\n",
       "          (glu_layers): ModuleList(\n",
       "            (0): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (1): GLU_Layer(\n",
       "              (fc): Linear(in_features=16, out_features=32, bias=False)\n",
       "              (bn): BatchNorm1d(32, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "              (dp): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (attn_transformers): ModuleList(\n",
       "      (0): AttentiveTransformer(\n",
       "        (fc): Linear(in_features=8, out_features=33, bias=False)\n",
       "        (bn): BatchNorm1d(33, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "        (mask): Sparsemax()\n",
       "      )\n",
       "      (1): AttentiveTransformer(\n",
       "        (fc): Linear(in_features=8, out_features=33, bias=False)\n",
       "        (bn): BatchNorm1d(33, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "        (mask): Sparsemax()\n",
       "      )\n",
       "      (2): AttentiveTransformer(\n",
       "        (fc): Linear(in_features=8, out_features=33, bias=False)\n",
       "        (bn): BatchNorm1d(33, eps=1e-05, momentum=0.02, affine=True, track_running_stats=True)\n",
       "        (mask): Sparsemax()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4 and 5. `TabTransformer` and the `Feature-Tokenizer Transformer`\n",
    "\n",
    "Details on the `TabTransformer` can be found in [TabTransformer: Tabular Data Modeling\n",
    "Using Contextual Embeddings](https://arxiv.org/pdf/2012.06678.pdf). The `FT-Transformer` is a variant introduced in the following two papers: [SAINT: Improved Neural Networks for Tabular Data\n",
    "via Row Attention and Contrastive Pre-Training](https://arxiv.org/pdf/2106.01342.pdf) and [Revisiting Deep Learning Models for Tabular Data](https://arxiv.org/pdf/2106.11959.pdf). The name itself (`FT-Transformer`) was first used in the latter, but the variant (which I will explain in a second) was already introduced in the `SAINT` paper. \n",
    "\n",
    "In general terms, the `TabTransformer` takes the embeddings from the categorical columns that are then passed through a Tranformer encoder, concatenated with the normalised continuous features, and then passed through an MLP. Let's have a look:\n",
    "\n",
    "<img src=\"../docs/figures/tabtransformer_arch.png\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "\n",
    "The dashed-border boxes indicate the the component is optional. In terms of the Transformer block, I am sure at this stage the reader has seen every possible diagram of The Transformer, its multihead attention etc, so I thought about drawing something that resembles more to the actual execution/code for each block. \n",
    "\n",
    "<img src=\"../docs/figures/transformer_block.png\" width=\"600\" align=\"center\"/>\n",
    "\n",
    "Note that this implementation assumes that the so called `inner-dim` (aka the projection dimension) is the same as the `dimension of the model` or, in this case, embedding dimension. Relaxing this assumption is relatively easy and programatically would involve including one parameter more in the `TabTransformer` class. For now, and consistent with other Transformer implementations, I will assume `inner-dim = dimension of the model`. Also, and again consistent other implementations, I assume that the Keys, Queries and Values are of the same `dim`. \n",
    "\n",
    "The architecture of the `FT-Transformer` is identical to that of the `TabTransformer` with the exception that the continuous cols are each passed through a 1-layer MLP with or without activation (referred in the figure below as `Cont Embeddings`) function before being concatenated with the continuous cols. \n",
    "\n",
    "<img src=\"../docs/figures/ft_transformer_arch.png\" width=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `FT-Transformer` with `pytorch-widedeep` is simply available by setting the param `embed_continuous` to `True`. In addition, I have also added the possibility of pooling all outputs from the transformer blocks using the `[CLS]` token. Otherwise all the outputs form the transformer blocks will be concatenated. Look at some of the other example notebooks for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n",
    "colnames = ['a', 'b', 'c', 'd', 'e']\n",
    "embed_input = [(u,i) for u,i in zip(colnames[:4], [4]*4)]\n",
    "continuous_cols = ['e']\n",
    "column_idx = {k:v for v,k in enumerate(colnames)}\n",
    "tab_transformer = TabTransformer(column_idx=column_idx, embed_input=embed_input, continuous_cols=continuous_cols)\n",
    "out = tab_transformer(X_tab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformer(\n",
       "  (cat_embed): Embedding(17, 32, padding_idx=0)\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cont_norm): Identity()\n",
       "  (transformer_blks): Sequential(\n",
       "    (block0): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block1): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block5): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Linear(in_features=129, out_features=516, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Linear(in_features=516, out_features=258, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_transformer = TabTransformer(\n",
    "    column_idx=column_idx, \n",
    "    embed_input=embed_input, \n",
    "    continuous_cols=continuous_cols,\n",
    "    embed_continuous=True,\n",
    "    embed_continuous_activation=\"relu\",\n",
    ")\n",
    "out = ft_transformer(X_tab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabTransformer(\n",
       "  (cat_embed): Embedding(17, 32, padding_idx=0)\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cont_norm): Identity()\n",
       "  (cont_embed): ContinuousEmbeddings(\n",
       "    (act_fn): ReLU(inplace=True)\n",
       "  )\n",
       "  (transformer_blks): Sequential(\n",
       "    (block0): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block1): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block5): TransformerEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Linear(in_features=160, out_features=640, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Linear(in_features=640, out_features=320, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, and as I mentioned earlier, note that `TabTransformer` class does not build the connection to the output neuron(s). This is done by the ``WideDeep`` class, which collects all wide and deep components and connects them to the output neuron(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6. `SAINT`\n",
    "\n",
    "\n",
    "Details on `SAINT` (Self-Attention and Intersample Attention Transformer) can be found in [SAINT: Improved Neural Networks for Tabular Data\n",
    "via Row Attention and Contrastive Pre-Training](https://arxiv.org/pdf/2106.01342.pdf). The main contribution of the saint model is the addition of an intersample attention block.  \n",
    "\n",
    "\n",
    "<img src=\"../docs/figures/saint_arch.png\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "In case you wonder what is this mysterious \"inter-sample attention\", simply, is the exact same mechanism as the well-known self-attention, but instead of features attending to each other here are observations/rows attending to each other. If you wanted to understand more details on what are the advantages of using this mechanism, I strongly encourage you to read the paper. Effectively, all that one needs to do is to reshape the input tensors of the transformer blocks and \"off we go\". \n",
    "\n",
    "`pytorch-widedeep`'s implementation is partially based in the [original code release](https://github.com/somepago/saint) (and the word \"*partially*\" is well used here in the sense that are notable differences, but in essence is the same implementation described in the paper).\n",
    "\n",
    "Let's have a look to some code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep.models import SAINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "?SAINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tab = torch.cat((torch.empty(5, 4).random_(4), torch.rand(5, 1)), axis=1)\n",
    "colnames = ['a', 'b', 'c', 'd', 'e']\n",
    "embed_input = [(u,i) for u,i in zip(colnames[:4], [4]*4)]\n",
    "continuous_cols = ['e']\n",
    "column_idx = {k:v for v,k in enumerate(colnames)}\n",
    "saint = SAINT(\n",
    "    column_idx=column_idx, \n",
    "    embed_input=embed_input, \n",
    "    continuous_cols=continuous_cols,\n",
    "    embed_continuous=True,\n",
    "    embed_continuous_activation=\"leaky_relu\",\n",
    ")\n",
    "out = saint(X_tab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (cat_embed): Embedding(17, 32, padding_idx=0)\n",
       "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cont_norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
       "  (cont_embed): ContinuousEmbeddings(\n",
       "    (act_fn): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "  )\n",
       "  (transformer_blks): Sequential(\n",
       "    (block0): SaintEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (self_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (self_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (self_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=160, out_features=480, bias=True)\n",
       "        (out_proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (row_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=160, out_features=640, bias=True)\n",
       "        (w_2): Linear(in_features=640, out_features=160, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (row_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block1): SaintEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (self_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (self_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (self_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=160, out_features=480, bias=True)\n",
       "        (out_proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (row_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=160, out_features=640, bias=True)\n",
       "        (w_2): Linear(in_features=640, out_features=160, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (row_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block2): SaintEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (self_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (self_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (self_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=160, out_features=480, bias=True)\n",
       "        (out_proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (row_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=160, out_features=640, bias=True)\n",
       "        (w_2): Linear(in_features=640, out_features=160, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (row_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block3): SaintEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (self_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (self_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (self_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=160, out_features=480, bias=True)\n",
       "        (out_proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (row_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=160, out_features=640, bias=True)\n",
       "        (w_2): Linear(in_features=640, out_features=160, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (row_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block4): SaintEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (self_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (self_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (self_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=160, out_features=480, bias=True)\n",
       "        (out_proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (row_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=160, out_features=640, bias=True)\n",
       "        (w_2): Linear(in_features=640, out_features=160, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (row_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (block5): SaintEncoder(\n",
       "      (self_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=32, out_features=96, bias=True)\n",
       "        (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (self_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (w_2): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (self_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (self_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn): MultiHeadedAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (inp_proj): Linear(in_features=160, out_features=480, bias=True)\n",
       "        (out_proj): Linear(in_features=160, out_features=160, bias=True)\n",
       "      )\n",
       "      (row_attn_ff): PositionwiseFF(\n",
       "        (w_1): Linear(in_features=160, out_features=640, bias=True)\n",
       "        (w_2): Linear(in_features=640, out_features=160, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (activation): GELU()\n",
       "      )\n",
       "      (row_attn_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (row_attn_ff_addnorm): AddNorm(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (ln): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (dense_layer_0): Sequential(\n",
       "        (0): Linear(in_features=160, out_features=640, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (dense_layer_1): Sequential(\n",
       "        (0): Linear(in_features=640, out_features=320, bias=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
